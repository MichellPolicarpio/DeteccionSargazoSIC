<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Samsung Innovation Campus - Detección de Sargazo</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="nav-menu">
        <button class="menu-toggle" aria-label="Abrir menú">
            <span></span>
            <span></span>
            <span></span>
        </button>
        <div class="nav-container">
            <a href="#inicio" class="nav-link">Inicio</a>
            <a href="#metodologia" class="nav-link">Metodología</a>
            <a href="https://colab.research.google.com/drive/1BQrcnOPRvfcF5NC9O2KST1Fas7E0239c?usp=sharing" class="nav-link">Notebook</a>
            <a href="#resultados" class="nav-link">Resultados</a>
            <a href="#equipo" class="nav-link">Integrantes</a>
        </div>
    </nav>

    <section id="inicio">
        <header class="header">
            <div class="logo-container">
                <img src="./siclogo.jpeg" alt="Samsung Logo" class="samsung-logo">
                <img src="./TKP.jpg" alt="UDEM Logo" class="udem-logo">
            </div>
            <h1>Detección automática de sargazo mediante Redes Neuronales Convolucionales</h1>
            <div class="subtitle">Proyecto final desarrollado para el programa Samsung Innovation Campus</div>
        </header>

        <main class="content">
            <section class="resumen">
                <h2>Resumen</h2>
                <p style="text-align: justify;">En este trabajo se presenta un modelo basado en inteligencia artificial para la detección automática de sargazo en playas mediante técnicas de visión computacional y redes neuronales convolucionales (CNN). Se implementó una arquitectura U-Net para segmentación semántica, entrenada con un conjunto de imágenes georreferenciadas provenientes de Mahahual, Quintana Roo, obtenidas entre 2019 y 2021. El modelo desarrollado logró identificar y cuantificar la presencia de sargazo con alta exactitud, alcanzando métricas de desempeño destacadas como una exactitud del 91% y un índice de intersección sobre unión (IoU) promedio de 82.48% en validación. La evaluación del sistema confirmó una alta concordancia entre clases predichas y reales, destacándose una precisión específica del 92% para la clase sargazo. Los resultados obtenidos demuestran la viabilidad del enfoque propuesto para monitoreo costero automatizado, ofreciendo una alternativa escalable y efectiva frente a métodos tradicionales.</p>
            </section>

            <section class="introduccion">
                <h2>I. Introducción</h2>
                <p style="text-align: justify;">El sargazo (Sargassum spp.) es una macroalga parda que flota en las aguas tropicales y subtropicales, y cuya llegada masiva a las costas —conocida como arribazón o "marea dorada"— representa un serio desafío para las autoridades ambientales y el sector turístico. Aunque esta biomasa ha sido considerada como recurso potencial para aplicaciones comerciales o energéticas, su alto contenido de contaminantes como arsénico ha generado preocupaciones ambientales y de salud pública. A esto se suma la dificultad logística y económica de su recolección y disposición adecuada (Devault et al., 2021).</p>

                <h3>1.1 Planteamiento del problema</h3>
                <p style="text-align: justify;">La acumulación masiva de sargazo en playas del Caribe y del Golfo de México ha generado afectaciones al turismo, la salud pública y los ecosistemas costeros. Sin embargo, el monitoreo en zonas costeras sigue siendo limitado, ya que depende en gran medida de observaciones visuales poco sistemáticas o de tecnologías que no siempre están al alcance de las comunidades locales.</p>
                <p style="text-align: justify;">El trabajo de Mohan & Strobl, (2024) documenta que la presencia de sargazo en las playas produce impactos negativos directos sobre la actividad turística, principalmente debido a su aspecto visual adverso y al olor desagradable que emite durante su descomposición, el cual genera molestias entre los visitantes e incrementa la proliferación de insectos. Se ha observado que, tras eventos de arribazón masiva, los turistas tienden a reducir el tiempo de permanencia en la playa o evitarla por completo, afectando la demanda de servicios locales como hospedaje, alimentos y actividades recreativas.</p>

                <h3>1.2 Justificación</h3>
                <p style="text-align: justify;">La aplicación de tecnologías avanzadas basadas en inteligencia artificial para el monitoreo del sargazo resulta esencial en la gestión ambiental costera. Este enfoque aporta beneficios significativos que optimizan el proceso y mejoran la toma de decisiones. Entre las ventajas clave se encuentran la capacidad de evaluar con precisión y en tiempo real la cobertura y distribución del sargazo, facilitando un seguimiento más eficiente de su dinámica.</p>
            </section>

            <section class="estadoarte">
                <h2>II. Estado del Arte</h2>
                <p style="text-align: justify;">Las macroalgas pardas flotantes de mar abierto del género Sargassum, principalmente Sargassum natans y S. fluitans, han habitado el océano Atlántico durante siglos, con registros históricos de su presencia en costas mexicanas como Veracruz. No obstante, desde 2011 se ha observado un incremento atípico en su proliferación, extendiéndose desde África occidental hasta el Gran Caribe y el Golfo de México.</p>
                <p style="text-align: justify;">El trabajo de Vasquez et al., (2022) propone estimar el nivel de acumulación de Sargassum en playas mediante fotografías tomadas con teléfonos inteligentes. Esta estrategia permite realizar evaluaciones rápidas y de bajo costo a partir de imágenes accesibles. Para lograr lo anterior, se construyó un conjunto de datos con más de mil imágenes recolectadas de redes sociales, clasificadas en cinco niveles de acumulación: ninguno, bajo, moderado, abundante y excesivo.</p>
            </section>

            <section id="metodologia" class="metodologia">
                <h2>III. Metodología</h2>
                <p style="text-align: justify;">La metodología se estructura en tres etapas principales: recopilación de datos, preprocesamiento de imágenes y desarrollo del sistema de clasificación. El enfoque se basa en técnicas de aprendizaje profundo para la segmentación semántica de sargazo, utilizando un conjunto de imágenes previamente anotadas y procesadas.</p>

                <h3>3.1 Recopilación y preprocesamiento de datos</h3>
                <p style="text-align: justify;">Se emplea un conjunto de imágenes georreferenciadas correspondientes a la localidad de Mahahual, Quintana Roo, obtenidas mediante crowdsourcing a través de la plataforma Collective View, durante el periodo comprendido entre septiembre de 2019 y agosto de 2021. Estas imágenes han sido previamente segmentadas mediante un modelo Pix2Pix, generando máscaras de anotación con clases diferenciadas, lo que permite utilizarlas directamente para tareas de segmentación semántica supervisada.</p>

                <h3>3.2 Preprocesamiento de Imágenes</h3>
                <p>El preprocesamiento de las imágenes se realizó manteniendo los tres canales RGB para preservar la información de color, lo que es crucial para la detección de sargazo. Las imágenes se redimensionaron a un tamaño uniforme de 256x256 píxeles para garantizar consistencia en el entrenamiento. Además, se normalizaron dividiendo los valores de píxeles por 255 para obtener valores entre 0 y 1, lo que ayuda a la convergencia del modelo durante el entrenamiento.</p>

                <h3>3.3 Implementación y Entrenamiento de la U-Net</h3>
                <p style="text-align: justify;">El sistema se implementa mediante una arquitectura de red neuronal convolucional basada en el modelo U-Net, utilizando bibliotecas especializadas en aprendizaje profundo como TensorFlow y Keras. El conjunto de datos de aproximadamente 1000 imágenes se dividió en un 80% para entrenamiento y 20% para validación. La arquitectura U-Net, conocida por su efectividad en tareas de segmentación, procesa las imágenes manteniendo su estructura espacial y preservando los detalles finos mediante conexiones entre capas. Un aspecto clave del entrenamiento fue el uso de imágenes previamente segmentadas mediante el modelo Pix2Pix, lo que permitió implementar un aprendizaje supervisado efectivo, donde el modelo aprendió a identificar patrones visuales del sargazo a partir de las máscaras de segmentación proporcionadas.</p>
            </section>

            <section id="resultados" class="resultados">
                <h2>IV. Resultados</h2>
                <p style="text-align: justify;">Durante el proceso de entrenamiento se monitorean métricas cuantitativas para evaluar el comportamiento del modelo. Se observa una disminución sostenida de la pérdida, acompañada de un incremento progresivo del desempeño en ambas métricas principales, sin que se presenten signos evidentes de sobreajuste.</p>
                
                <div class="metricas-container">
                    <div class="metrica-item">
                        <h3>Pérdida (Loss)</h3>
                        <p>0.3822</p>
                        <div class="tooltip">
                            <button class="info-btn">ℹ️</button>
                            <div class="tooltip-content">
                                <h4>Pérdida (Loss)</h4>
                                <p>La pérdida (loss) es una medida que indica qué tan bien está funcionando el modelo durante el entrenamiento. Un valor de 0.3822 es muy bueno porque:</p>
                                <ul>
                                    <li>Indica que el modelo está aprendiendo correctamente</li>
                                    <li>Muestra que las predicciones están muy cerca de los valores reales</li>
                                    <li>Un valor bajo de pérdida significa que el modelo está generalizando bien</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="metrica-item">
                        <h3>Precisión (Accuracy)</h3>
                        <p>91.45%</p>
                        <div class="tooltip">
                            <button class="info-btn">ℹ️</button>
                            <div class="tooltip-content">
                                <h4>Precisión (Accuracy)</h4>
                                <p>La precisión del 91.45% es excelente porque:</p>
                                <ul>
                                    <li>Indica que el modelo clasifica correctamente más del 90% de los casos</li>
                                    <li>Es superior al umbral comúnmente aceptado del 85% para modelos de segmentación</li>
                                    <li>Demuestra que el modelo es altamente confiable para la detección de sargazo</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="metrica-item">
                        <h3>Mean IoU</h3>
                        <p>82.48%</p>
                        <div class="tooltip">
                            <button class="info-btn">ℹ️</button>
                            <div class="tooltip-content">
                                <h4>Mean IoU (Intersección sobre Unión)</h4>
                                <p>El Mean IoU del 82.48% es muy bueno porque:</p>
                                <ul>
                                    <li>Mide la precisión de la segmentación superpuesta</li>
                                    <li>Un valor superior al 80% indica una excelente coincidencia entre las predicciones y las máscaras reales</li>
                                    <li>Demuestra que el modelo puede identificar con precisión los límites del sargazo</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="resultados-preliminares">
                    <h3>Resultados del Modelo</h3>
                    <div class="resultados-imagen-container">
                        <img src="./Fig1_InputMask.jpg" alt="Imagen de entrada y máscara segmentada" class="resultados-imagen" style="width: 80%; max-width: 800px;">
                        <img src="./Fig2_MetricsEvolution.jpg" alt="Evolución de métricas" class="resultados-imagen" style="width: 80%; max-width: 800px;">
                        <img src="./Fig3_ConfusionMatrix.jpg" alt="Matriz de confusión" class="resultados-imagen" style="width: 80%; max-width: 800px;">
                        <img src="./Fig4_ResultsVisualization.jpg" alt="Visualización de resultados" class="resultados-imagen" style="width: 80%; max-width: 800px;">
                        <div class="interpretacion-resultados">
                            <h4>Interpretación de los Resultados:</h4>
                            <p style="text-align: justify;">El entrenamiento se estabiliza mediante el ajuste dinámico de la tasa de aprendizaje con ReduceLROnPlateau y la restauración de pesos con base en la mejor época validada. Estas estrategias contribuyen a mejorar la capacidad de generalización del modelo.</p>
                            
                            <p style="text-align: justify;">En la evaluación sobre el conjunto de prueba, se observa una alta concordancia entre las clases predichas y las verdaderas:</p>
                            <ul>
                                <li><strong>Clase Sargazo (Clase 1):</strong> 92% de precisión</li>
                                <li><strong>Clase Arena (Clase 0):</strong> 85% de precisión</li>
                                <li><strong>Clase Otros (Clase 2):</strong> 94% de precisión</li>
                            </ul>

                            <p style="text-align: justify;">Las imágenes muestran el rendimiento del modelo en la segmentación de sargazo:</p>
                            <ul>
                                <li><strong>Imagen de Entrada:</strong> La fotografía original de la playa con presencia de sargazo.</li>
                                <li><strong>Máscara Real:</strong> La segmentación manual realizada, donde:
                                    <ul>
                                        <li>Amarillo (Clase 0): Representa la arena de la playa</li>
                                        <li>Rojo oscuro (Clase 1): Indica la presencia de sargazo</li>
                                        <li>Gris (Clase 2): Señala otras áreas como agua o vegetación</li>
                                    </ul>
                                </li>
                                <li><strong>Máscara Predicha:</strong> La segmentación generada por nuestro modelo, utilizando el mismo esquema de colores.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <section class="discusion">
                <h2>V. Discusión y Conclusiones</h2>
                <p style="text-align: justify;">El modelo propuesto mostró una efectividad significativa en la detección automática de sargazo, lo que confirma la idoneidad de las redes neuronales convolucionales en aplicaciones ambientales. La implementación de una arquitectura U-Net permitió lograr segmentaciones precisas y consistentes, incluso en escenarios visualmente complejos.</p>
                <p style="text-align: justify;">No obstante, se identificaron limitaciones relacionadas con la calidad y diversidad del conjunto de datos, especialmente en situaciones con bajo contraste visual o colores similares al sargazo. Por ello, futuras investigaciones podrían centrarse en ampliar el conjunto de datos, considerando diversas condiciones ambientales y privilegiando la creación de un conjunto de datos específico para playas del Golfo de México, incrementando así la robustez del modelo y su relevancia regional.</p>
                <p style="text-align: justify;">Finalmente, se concluye que el sistema desarrollado constituye una herramienta tecnológica prometedora para la gestión ambiental costera, capaz de proporcionar información precisa y oportuna que facilite decisiones operativas.</p>
            </section>

            <section class="agradecimientos">
                <h2>Agradecimientos</h2>
                <p style="text-align: justify;">Agradecemos al programa Samsung Innovation Campus por la oportunidad de desarrollar este proyecto final, que nos permitió aplicar los conocimientos adquiridos en inteligencia artificial y visión computacional. También extendemos nuestro agradecimiento a los profesores y mentores que nos guiaron durante el desarrollo del proyecto, así como a los colaboradores que participaron en la recolección y procesamiento de las imágenes utilizadas en este estudio.</p>
            </section>
        </main>

        <section class="recursos-adicionales">
            <h2>Recursos Adicionales</h2>
            <div class="recursos-grid">
                <a href="https://uvmx-my.sharepoint.com/:u:/g/personal/zs21002379_estudiantes_uv_mx/EZ7fF12kY2hKmW8OQqnlVcgB8oCX3T1JPDF6rgQje_7Yiw?e=Vlvih8" class="recurso-card" target="_blank">
                    <div class="recurso-icon">📓</div>
                    <h3>Notebook del Proyecto</h3>
                    <p>Descarga el notebook con todo el código y análisis detallado</p>
                </a>
                <a href="https://github.com/MichellPolicarpio/DeteccionSargazoSIC/" class="recurso-card" target="_blank">
                    <div class="recurso-icon">💻</div>
                    <h3>Repositorio GitHub</h3>
                    <p>Explora el código fuente completo del proyecto</p>
                </a>
                <a href="https://figshare.com/articles/dataset/Sargassum_Segmented_Dataset/16550166?file=30598743" class="recurso-card" target="_blank">
                    <div class="recurso-icon">📊</div>
                    <h3>Dataset Utilizado</h3>
                    <p>Dataset de imágenes segmentadas de sargazo recopiladas mediante ciencia ciudadana</p>
                </a>
                <a href="https://uvmx-my.sharepoint.com/:b:/g/personal/zs21002379_estudiantes_uv_mx/ETTRX30vakNDkzd_f5WmRi8BQmVRtDtcMESGTQP1jSIEZQ?e=5nxWyv" class="recurso-card" target="_blank">
                    <div class="recurso-icon">📝</div>
                    <h3>Documentación Técnica</h3>
                    <p>Consulta la documentación detallada del proyecto</p>
                </a>
            </div>
        </section>

        <footer class="piepagina">
            <section id="equipo" class="team-carousel">
                <h3>Nuestro Equipo</h3>
                <div class="carousel-container">
                    <button class="carousel-button prev">&#10094;</button>
                    <div class="carousel-track">
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./isabella.jpg" alt="Isabella Coria" class="foto-isabella">
                            </div>
                            <h4>Isabella Coria Juarez</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./lizette.jpg" alt="Lizette Hernández" class="foto-lizette">
                            </div>
                            <h4>Lizette Ariadna Hernández Ortiz</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./michell.jpg" alt="Michell Policarpio" class="foto-michell">
                            </div>
                            <h4>Michell Alexis Policarpio Moran</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./brandon.jpg" alt="Brandon Mota" class="foto-brandon">
                            </div>
                            <h4>Brandon Josafat Mota López</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./alexis.jpg" alt="Alexis Rivera" class="foto-alexis">
                            </div>
                            <h4>Alexis Rivera Merlin</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./victor.jpg" alt="Victor Moreno" class="foto-victor">
                            </div>
                            <h4>Victor Daniel Moreno Luna</h4>
                        </div>
                    </div>
                    <button class="carousel-button next">&#10095;</button>
                </div>
            </section>
          
            <div class="copyright">
                <p>© 2025 Todos los derechos reservados.</p>
                <p>Este trabajo fue desarrollado como parte del programa Samsung Innovation Campus.</p>
            </div>
        </footer>
    </section>
    <script src="script.js"></script>
</body>
</html> 