<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Samsung Innovation Campus - Detecci√≥n de Sargazo</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="nav-menu">
        <button class="menu-toggle" aria-label="Abrir men√∫">
            <span></span>
            <span></span>
            <span></span>
        </button>
        <div class="nav-container">
            <a href="#inicio" class="nav-link">Inicio</a>
            <a href="#metodologia" class="nav-link">Metodolog√≠a</a>
            <a href="https://colab.research.google.com/drive/1F9jBLcWd1ITPgZSNDlnn7EnJUWNGxWPB?usp=sharing" class="nav-link">Notebook</a>
            <a href="#resultados" class="nav-link">Resultados</a>
            <a href="#equipo" class="nav-link">Integrantes</a>
        </div>
    </nav>

    <section id="inicio">
        <header class="header">
            <div class="logo-container">
                <img src="./siclogo.jpeg" alt="Samsung Logo" class="samsung-logo">
                <img src="./udemlogo.jpeg" alt="UDEM Logo" class="udem-logo">
            </div>
            <h1>Proyecto Final<br>Samsung Innovation Campus</h1>
            <div class="subtitle">Detecci√≥n de sargazo en playas veracruzanas mediante t√©cnicas de visi√≥n por computadora y redes neuronales</div>
        </header>

        <main class="content">
            <section class="introduccion">
                <h2>I. Introducci√≥n</h2>
                <p style="text-align: justify;">El sargazo (Sargassum spp.) es una macroalga parda que flota en las aguas tropicales y subtropicales, y cuya llegada masiva
                a las costas ‚Äîconocida como arribaz√≥n o "marea dorada"‚Äî representa un serio desaf√≠o para las autoridades ambientales y el sector tur√≠stico. 
                Aunque esta biomasa ha sido considerada como recurso potencial para aplicaciones comerciales o energ√©ticas, su alto contenido de contaminantes 
                como ars√©nico ha generado preocupaciones ambientales y de salud p√∫blica. A esto se suma la dificultad log√≠stica y econ√≥mica de su recolecci√≥n y
                disposici√≥n adecuada (Devault et al., 2021).</p>
                <p style="text-align: justify;">En este contexto, el trabajo de (Arellano-Verdejo & Lazcano-Hern√°ndez, 2021) la visi√≥n por computadora ha emergido como una herramienta clave
                para el monitoreo automatizado del sargazo, permitiendo procesar grandes vol√∫menes de im√°genes de manera eficiente. En particular, las redes 
                neuronales convolucionales (CNN) han demostrado un alto desempe√±o en tareas de clasificaci√≥n de im√°genes relacionadas con la presencia o 
                ausencia de sargazo en playas.
                Estas t√©cnicas ofrecen una alternativa prometedora al monitoreo visual tradicional realizado por personas, ya que permiten generar informaci√≥n
                georreferenciada con mayor rapidez, consistencia y escalabilidad.
                </p>
                <p style="text-align: justify;">Como se√±alan (Lazcano-Hernandez et al., (2023), los avances en inteligencia artificial y la incorporaci√≥n de nuevas disciplinas han abierto 
                portunidades importantes para innovar en el monitoreo costero, un campo que contin√∫a enfrentando retos fundamentales.</p>
            </section>

            <section class="problema">
                <h2>II. Planteamiento del Problema</h2>
                <p style="text-align: justify;">La acumulaci√≥n masiva de sargazo en playas del Caribe y del Golfo de M√©xico, como en Veracruz (Luis God√≠nez-Ortega et al., 2021), ha generado
                    afectaciones al turismo, la salud p√∫blica y los ecosistemas costeros. Sin embargo, el monitoreo en zonas costeras sigue siendo limitado, ya
                    que depende en gran medida de observaciones visuales poco sistem√°ticas o de tecnolog√≠as que no siempre est√°n al alcance de las comunidades 
                    locales.</p>
                <p style="text-align: justify;">Existe la necesidad de soluciones tecnol√≥gicas m√°s accesibles, capaces de detectar y clasificar la presencia de sargazo de manera automatizada. 
                    En este contexto, la visi√≥n por computadora y el uso de redes neuronales ofrecen una alternativa viable y escalable para apoyar la toma de decisiones 
                    en tiempo oportuno, con potencial para fortalecer la resiliencia local frente a este fen√≥meno. </p>
            </section>

            <section class="objectivos">
                <h2>III. Objetivos</h2>
                <p style="text-align: justify;"> Desarrollar un modelo computacional basado en segmentaci√≥n sem√°ntica que permita identificar y clasificar por
                    p√≠xel la presencia de sargazo en im√°genes de playas veracruzanas,con el fin de generar informaci√≥n espacial detallada que contribuya al 
                    monitoreo costero. </p>
                <p style="text-align: justify;">El enfoque propuesto busca facilitar la detecci√≥n automatizada del sargazo mediante visi√≥n por computadora y 
                    aprendizaje profundo, favoreciendo su implementaci√≥n en contextos locales como una herramienta accesible, eficiente y escalable para la gesti√≥n
                    ambiental.</p>
            </section>

            <section class="estadoarte">
                <h2>IV. Estado del arte</h2>
                
            </section>

            <section id="metodologia" class="metodologia">
                <h2>V. Metodolog√≠a</h2>
                <p style="text-align: justify;"> El dise√±o del sistema para la detecci√≥n de sargazo en playas se abord√≥ mediante una metodolog√≠a estructurada en distintas fases, priorizando la solidez t√©cnica, la eficiencia computacional y la claridad en la organizaci√≥n del c√≥digo. Se incorporaron 
                    t√©cnicas de inteligencia artificial orientadas a visi√≥n por computadora, aplicadas sobre im√°genes costeras segmentadas sem√°nticamente.</p>

                <p style="text-align: justify;">Una etapa fundamental fue la obtenci√≥n del dataset, el cual se tom√≥ de una plataforma abierta, a partir trabajo de Arellano-Verdejo & Lazcano-Hern√°ndez, (2021). 
                    Dicho conjunto de im√°genes fue generado a partir de fotograf√≠as georreferenciadas recopiladas mediante esquemas de crowdsourcing en la plataforma Collective View, enfocada en capturas a escala
                    de playa en la regi√≥n de Mahahual, Quintana Roo (M√©xico), entre septiembre de 2019 y agosto de 2021. Aunque las im√°genes presentaban variaciones t√©cnicas, visuales y temporales fuera del control
                    de los autores originales, estas resultaron ser una fuente √∫til para el entrenamiento de modelos de segmentaci√≥n autom√°tica.</p>

                <p style="text-align: justify;">El conjunto incluye im√°genes segmentadas mediante el modelo Pix2Pix, una arquitectura basada en redes generativas 
                    adversariales (GANs) adaptadas para tareas de segmentaci√≥n sem√°ntica. A partir de estas segmentaciones, fue posible construir mapas de cobertura de 
                    Sargassum por p√≠xel, sirviendo como referencia para el entrenamiento supervisado de modelos adicionales y para la validaci√≥n de nuevas predicciones.
                    La metodolog√≠a completa abarca el preprocesamiento de datos, el entrenamiento de modelos basados en redes neuronales convolucionales 
                    para segmentaci√≥n sem√°ntica, y la validaci√≥n experimental orientada al monitoreo automatizado de sargazo en entornos costeros.</p>
                </p>
                <h3>V. I Preprocesamiento de datos</h3>
                <p style="text-align:justify">El preprocesamiento del conjunto de datos se dise√±√≥ de forma modular utilizando TensorFlow, con im√°genes redimensionadas a 256√ó256 p√≠xeles y normalizadas en el rango [0, 1]. Las m√°scaras, codificadas por color, fueron convertidas en etiquetas por p√≠xel mediante un mapeo RGB a clases discretas. Se definieron los colores de clase de la siguiente forma:</p>
                
                <div class="code-block">
                    <div class="code-block-wrapper">
                        <code>CLASS_COLORS = np.array([
    [255, 255, 0],   # Clase 0
    [139, 0, 0],     # Clase 1
    [192, 192, 192]  # Clase 2
]) / 255.0</code>
                    </div>
                </div>

                <p style="text-align:justify">La funci√≥n de carga y conversi√≥n de m√°scaras se basa en la comparaci√≥n de cada p√≠xel con los colores definidos, utilizando distancia euclidiana y selecci√≥n por argmin.
                    El proceso completo se encapsul√≥ en una funci√≥n load_image_and_mask(), utilizada en un pipeline de tf.data.Dataset.</p>
                
                <div class="code-block">
                    <code>dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))
dataset = dataset.map(load_image_and_mask)
dataset = dataset.shuffle(100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)</code>
                </div>

                <p style="text-align:justify">Adem√°s, se implement√≥ una m√©trica personalizada basada en MeanIoU, con conversi√≥n autom√°tica de salidas softmax a clases mediante argmax.</p>
                
                <div class="code-block">
                    <code>class ArgmaxMeanIoU(MeanIoU):
    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.argmax(y_pred, axis=-1)
        return super().update_state(y_true, y_pred, sample_weight)</code>
                </div>

                <p style="text-align:justify">Este flujo asegura eficiencia en la carga de datos, mantiene la consistencia del formato de entrada, y permite escalar f√°cilmente a otros conjuntos o configuraciones.</p>

                <h3>5.2. Arquitectura del modelo</h3>
                <p style="text-align:justify">El modelo empleado para la segmentaci√≥n sem√°ntica fue implementado utilizando la arquitectura U-Net, reconocida por su eficacia en tareas de segmentaci√≥n a nivel de p√≠xel. Esta red se compone de dos rutas principales: un codificador (encoder) que extrae caracter√≠sticas espaciales mediante convoluciones y pooling, y un decodificador (decoder) que reconstruye la segmentaci√≥n usando upsampling y concatenaciones de activaciones intermedias.</p>

                <div class="code-block">
                    <code>inputs = Input(shape=(256, 256, 3))
c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
p1 = MaxPooling2D((2, 2))(c1)
# ...
u5 = UpSampling2D((2, 2))(c4)
outputs = Conv2D(3, (1, 1), activation='softmax')(c5)</code>
                </div>

                <p style="text-align:justify">El modelo fue compilado con el optimizador Adam, funci√≥n de p√©rdida sparse_categorical_crossentropy, y la m√©trica MeanIoU adaptada para clasificaciones discretas:</p>

                <div class="code-block">
                    <code>model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy', ArgmaxMeanIoU(num_classes=3)]
)</code>
                </div>

                <h3>V. III Entrenamiento del modelo</h3>
                <p style="text-align:justify">El entrenamiento del modelo se llev√≥ a cabo utilizando el conjunto de datos previamente procesado y estructurado en lotes. Se emple√≥ la funci√≥n model.fit() de TensorFlow para realizar el ajuste de pesos a lo largo de m√∫ltiples √©pocas, utilizando validaci√≥n cruzada con el conjunto de prueba.</p>

                <div class="code-block">
                    <code>checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'best_model.keras',
    monitor='val_loss',
    save_best_only=True,
    mode='min'
)

history = model.fit(
    train_dataset,
    validation_data=test_dataset,
    epochs=EPOCHS,
    callbacks=[checkpoint]
)</code>
                </div>
                
            </section>

            <section id="resultados" class="resultados">
                <h2>VI. Resultados</h2>
                <div class="metricas-container">
                    <div class="metrica-item">
                        <img src="./ExactitudDuranteEntrenamiento.jpg" alt="Gr√°fica de Exactitud durante el Entrenamiento" class="metrica-grafica grafica-hover">
                        <p class="pie-foto">Exactitud del modelo durante el entrenamiento, mostrando la convergencia del aprendizaje</p>
                    </div>
                    <div class="metrica-item">
                        <img src="./IoUDuranteEntrenamiento.jpg" alt="Gr√°fica de IoU durante el Entrenamiento" class="metrica-grafica grafica-hover">
                        <p class="pie-foto">√çndice de IoU durante el entrenamiento, indicando la precisi√≥n de la segmentaci√≥n</p>
                    </div>
                    <div class="metrica-item">
                        <img src="./PerdidaDuranteEntrenamiento.jpg" alt="Gr√°fica de P√©rdida durante el Entrenamiento" class="metrica-grafica grafica-hover">
                        <p class="pie-foto">Funci√≥n de p√©rdida durante el entrenamiento, mostrando la optimizaci√≥n del modelo</p>
                    </div>
                </div>

                <div class="resultados-preliminares">
                    <h3>Resultados Preliminares del Dataset</h3>
                    <div class="resultados-imagen-container">
                        <img src="./ResultadosPreliminaresDataset.jpg" alt="Resultados Preliminares del Dataset" class="resultados-imagen">
                        <div class="interpretacion-resultados">
                            <h4>Interpretaci√≥n de los Resultados:</h4>
                            <p style="text-align: justify;">Las im√°genes muestran el rendimiento del modelo en la segmentaci√≥n de sargazo. En cada fila se presentan tres elementos:</p>
                            <ul>
                                <li><strong>Imagen de Entrada:</strong> La fotograf√≠a original de la playa con presencia de sargazo.</li>
                                <li><strong>M√°scara Real:</strong> La segmentaci√≥n manual realizada por expertos, donde:
                                    <ul>
                                        <li>Amarillo (Clase 0): Representa la arena de la playa</li>
                                        <li>Rojo oscuro (Clase 1): Indica la presencia de sargazo</li>
                                        <li>Gris (Clase 2): Se√±ala otras √°reas como agua o vegetaci√≥n</li>
                                    </ul>
                                </li>
                                <li><strong>M√°scara Predicha:</strong> La segmentaci√≥n generada por nuestro modelo, utilizando el mismo esquema de colores.</li>
                            </ul>
                            <p style="text-align: justify;">Como se puede observar, el modelo logra una segmentaci√≥n bastante precisa, identificando correctamente las √°reas con sargazo y diferenci√°ndolas de la arena y otros elementos del entorno. La comparaci√≥n entre las m√°scaras reales y predichas muestra una alta coincidencia en la delimitaci√≥n de las diferentes clases, lo que valida la efectividad del modelo para esta tarea de segmentaci√≥n.</p>
                        </div>
                    </div>
                </div>

                <div class="tablacontenido">
                    <table>
                        <caption>Tabla 1. </caption>
                        <thead>
                            <tr>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                                <th>Categor√≠a</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>Contenido</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
                            <tr><td>Contenido</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
                            <tr><td>Contenido</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
                            <tr><td>Contenido</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
                            <tr><td>Contenido</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
                        </tbody>
                    </table>
                    <div class="notastabla">
                        <p>Nota: nota de la tabla en caso de ser necesaria</p>
                        <p>Referencia: Tomada de: "T√≠tulo de la referencia" por Autor (es). A√±o, T√≠tulo. P√°gina</p>
                    </div>
                </div>
            </section>
        </main>

        <section class="recursos-adicionales">
            <h2>Recursos Adicionales</h2>
            <div class="recursos-grid">
                <a href="https://colab.research.google.com/drive/1F9jBLcWd1ITPgZSNDlnn7EnJUWNGxWPB?usp=sharing" class="recurso-card" target="_blank">
                    <div class="recurso-icon">üìì</div>
                    <h3>Notebook del Proyecto</h3>
                    <p>Accede al notebook de Google Colab con todo el c√≥digo y an√°lisis detallado</p>
                </a>
                <a href="https://github.com/MichellPolicarpio/DeteccionSargazoSIC/" class="recurso-card" target="_blank">
                    <div class="recurso-icon">üíª</div>
                    <h3>Repositorio GitHub</h3>
                    <p>Explora el c√≥digo fuente completo del proyecto</p>
                </a>
                <a href="https://figshare.com/articles/dataset/Sargassum_Segmented_Dataset/16550166?file=30598743" class="recurso-card" target="_blank">
                    <div class="recurso-icon">üìä</div>
                    <h3>Dataset Utilizado</h3>
                    <p>Dataset de im√°genes segmentadas de sargazo recopiladas mediante ciencia ciudadana</p>
                </a>
                <a href="https://uvmx-my.sharepoint.com/:w:/g/personal/zs21002379_estudiantes_uv_mx/EQ5rz_gQGTFFnSw-fdeyZR0Bz6wK4l7NJAn-tIv1m1aBBw?e=HxpOwe" class="recurso-card" target="_blank">
                    <div class="recurso-icon">üìù</div>
                    <h3>Documentaci√≥n T√©cnica</h3>
                    <p>Consulta la documentaci√≥n detallada del proyecto</p>
                </a>
            </div>
        </section>

        <footer class="piepagina">
            <section id="equipo" class="team-carousel">
                <h3>Nuestro Equipo</h3>
                <div class="carousel-container">
                    <button class="carousel-button prev">&#10094;</button>
                    <div class="carousel-track">
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./isabella.jpg" alt="Isabella Coria" class="foto-isabella">
                            </div>
                            <h4>Isabella Coria Juarez</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./lizette.jpg" alt="Lizette Hern√°ndez" class="foto-lizette">
                            </div>
                            <h4>Lizette Ariadna Hern√°ndez Ortiz</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./michell.jpg" alt="Michell Policarpio" class="foto-michell">
                            </div>
                            <h4>Michell Alexis Policarpio Moran</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./brandon.jpg" alt="Brandon Mota" class="foto-brandon">
                            </div>
                            <h4>Brandon Josafat Mota L√≥pez</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./alexis.jpg" alt="Alexis Rivera" class="foto-alexis">
                            </div>
                            <h4>Alexis Rivera Merlin</h4>
                        </div>
                        <div class="team-member">
                            <div class="member-photo">
                                <img src="./victor.jpg" alt="Victor Moreno" class="foto-victor">
                            </div>
                            <h4>Victor Daniel Moreno Luna</h4>
                        </div>
                    </div>
                    <button class="carousel-button next">&#10095;</button>
                </div>
            </section>
          
            <div class="copyright">
                <p>¬© 2025 Samsung Innovation Campus - UDEM. Todos los derechos reservados.</p>
                <p>Este trabajo fue desarrollado como parte del programa Samsung Innovation Campus en colaboraci√≥n con la Universidad de M√©xico.</p>
            </div>
        </footer>
    </section>

    <script src="script.js"></script>
</body>
</html> 